
>原创内容，转载请注明作者与来源。

---

地学是一门观测科学，但随着计算机技术的不断发展，其逐渐演变为观测和数值模式并重的发展特点。就物理海洋学来说，相较于物理公式的理论推导，基于数值模式的诊断分析研究目前已成为主流。所以，你可以称其为“物理海洋学”，但如果有人称其为“数据分析学-物理海洋”，貌似也无大碍。

随着数值模式分辨率的不断提高，我们迎来了数据的“大爆炸时代”。有好处的同时必然也伴随着坏处，即使忽略掉大数据存储所带来的资金成本压力，大数据处理带来的时间成本压力也在逐渐增加。在这一背景下，选择matlab还是python？这是个问题。

Cosmic Passerby入门matlab有个7-8年，了解python也有个1-2年。他有次对我说，matlab像一个严谨的数学家，而python则像一个散漫的小说家，但如果你的目标是进行大数据的处理工作，他强烈建议 **all in python**。无它，python做到了1+1+1>>3，这3个1分别是python，vscode和 github。

---

## 代码的自动化工程
### github copilot + vscode
在直接比较matlab和python的数据处理速度前，Cosmic Passerby 强烈要求先跟我谈谈代码的自动化工程：使用过linux系统`tab`键自动补全功能的人，大概都会喜欢上这种便捷性。[GitHub](https://github.com/ "GitHub")是一家伟大的公司，因为它实现了任何文本（包括代码）撰写的自动化过程，通过[GitHub Copilot](https://github.com/features/copilot "github copilot")。在代码撰写时，我们只需要在注释行描述我们后面代码的大概功能，`copilot`就会自动生成相关代码。当然了，我们也能手动敲击代码，`copilot`会自行补全，所以，当你认可它的时候敲击`tab`键，不认可它时仍自行编写即可。有时候，你可能不清楚最高效、最简洁的数据处理方法，但`copilot`可能正好知道。所以，就让我们来说些不太正经的人话，让`copilot`去说正经的机器话吧。这个高效的功能授权任何人每周免费使用2000次，而如果你是在读学生或从事教育相关行业的人（指拥有edu后缀邮箱），那恭喜你了，只要通过了[GitHub Education](https://github.com/education "GitHub Education")认证，你便可以无限制地，随心所欲地使用`copilot`。是吧，github是一家伟大的公司。VScode中就恰好支持插件。

## 代码的版本控制和可移植性
### Git + github
Cosmic Passerby固执地对我说，他必须要给我讲完该部分内容才肯给我聊聊matlab和python在数据处理速度上的优劣：我们日常撰写代码、文档总会遇到文件修改备份的情况，撰写了一堆后缀version1、version2或者版本1、版本2的文件，最终导致了文件的繁多、混乱、不易找寻。[Git](https://git-scm.com/ "Git")作为一个版本控制器，可以有效记录我们对文件的修改过程，并可随时查看之前的版本信息。好处显而易见，文件数量少了，信息简洁了。截止目前我们的git还是一个本地版本控制器，所有修改信息都储存在本地的.git文件中，更进一步，我们能否进行云存储呢？对于任何人，github都给到一定空间的免费云存储，这样，我们可以把文件上传（`push`）到github上，或者拉回（`pull`）到任何一个联网的终端电脑上，就比如个人超算（HPC）账户中。是的，你发现了，通过github，你可以轻松实现代码的一键移植[](https://git-scm.com/docs/git-push "")。这样一方面可以解决数据丢失焦虑（云端备份），另一方面可以让我们在任何电脑（平板）上的代码修改都可以同步更新。github真是一家……
我们已经聊了两件事，代码的自动化与移植性，为什么我们不提matlab和python呢？是因为其实对于任何文件，上述操作都可行。回到大数据，如果我们想用HPC来处理，那么第一python本身就非商业软件，免费安装不担心商业风险；第二vscode可满足python文件的直接执行，这就不需要另外启动matlab软件执行命令（前提是所用的HPC计算节点可通过SSH连接），总的来看，python小优。

## 计算内存与分布式计算
### xarray + dask + Client
Cosmic Passerby终于愿意谈谈大数据的处理速度问题：matlab本身是一个严谨的数学家，对于大部分文件，他必须一次导入所需数据随后计算，如果数据过大，其本身就占据cpu的大量内存，那么后续计算速度缓慢就显而易见。python是个散漫的小说家，他本身不会处理数据，但是他找来了[Xarray](https://docs.xarray.dev/en/stable/index.html "Xarray")，[Dask](https://docs.dask.org/en/stable/index.html "Dask")等模块来解决这个问题。对于大数据本身，xarray支持缓处理，你在读取数据的时候可以进行分块处理，如：
```
import xarray as xr
ds = xr.open_dataset("big_data.nc", chunks={"time": 100})

```
上述代码的含义是：按 `time` 维度每 100 个时间步为一个块读取数据,在计算的时候每次只加载一块，释放后再加载，这就防止了数据读取造成的“慢+卡+死”。

python同时也支持分布式计算，通过dask模块。我们之前已经将数据切块了，通过`chunk`，如果我们有足够的计算资源，是不是可以分块并行计算，时间成本就节约了。HPC不必多说，即使是单个笔记本，因为其本身就是多核，所以也建议对较为复杂的计算进行分布式处理：
```
from dask.distributed import Client
client = Client()

# 可选：查看 dashboard 地址
print(client.dashboard_link)

# 创建一个 Dask 数组（懒加载）
import dask.array as da
x = da.random.random((10000, 10000), chunks=(1000, 1000))
mean = x.mean()  # 不立即计算

result = mean.compute()  # 调度执行
```

上述代码执行后我们会得到一个[Dashboard](https://docs.dask.org.cn/en/stable/dashboard.html "daskboard")的链接网址，点击进入后就可实时查看数据的处理过程，根据`task stream`的资源分配情况二次调整`chunk`大小，保证算力得到最优使用。

![Daskboard模板（来自官网）](https://docs.dask.org.cn/en/stable/_images/dashboard_status.png)

## 小结
所以选择matlab还是python？这是个问题吗？对于大数据处理来说显然不是。尤其是对两者都还不熟悉的入门学者。

---